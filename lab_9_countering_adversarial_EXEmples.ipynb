{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Countering Adversarial EXEmples\n",
    "\n",
    "Contents:\n",
    "- Adversarial Training\n",
    "    - GAMMA section injection against Adversarial Training\n",
    "\n",
    "\n",
    "In this last laboratory, we show how to *learn* a defense against adversarial EXEmples.\n",
    "This laboratory is based on two recent papers:\n",
    "\n",
    "* Lucas, K., Pai, S., Lin, W., Bauer, L., Reiter, M. K., & Sharif, M. (2023). Adversarial training for Raw-Binary malware classifiers. In 32nd USENIX Security Symposium (USENIX Security 23) (pp. 1163-1180).\n",
    "\n",
    "* Kozak, M., Demetrio, L., Trizna, D., & Roli, F. (2024). Updating Windows Malware Detectors: Balancing Robustness and Regression against Adversarial EXEmples. arXiv preprint arXiv:2405.02646.\n",
    "\n",
    "Both papers treat defenses against adversarial attacks, leveraging *adversarial training*, which means that, at training time, samples are perturbed to become EXEmples and included in data to help the model to generalize on these threats as well.\n",
    "\n",
    "Hence, in this lab, we will use adversarially-trained models to show their increased strenght against EXEmples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf malware_lab_files\n",
    "!git clone https://github.com/dtrizna/malware_lab_files.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy==1.25.2 scikit-learn==1.1.1 # we need specific versions of these packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install lief==0.12.3 git+https://github.com/dtrizna/ember.git secml_malware yara-python py7zr==0.19.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys # force reimport of lab_helpers\n",
    "if 'malware_lab_files.helpers' in sys.modules:\n",
    "    del sys.modules['malware_lab_files.helpers']\n",
    "\n",
    "from malware_lab_files.helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ember_weights_local_path = os.path.join(\"malware_lab_files\", \"models\", \"ember_model.txt.7z\")\n",
    "at_ember_weights_local_path = os.path.join(\"malware_lab_files\", \"models\", \"at_ember_model.txt.7z\")\n",
    "ember_pretrained_weights = get_encrypted_archive(ember_weights_local_path, password=\"\")\n",
    "at_ember_pretrained_weights = get_encrypted_archive(at_ember_weights_local_path, password=\"\")\n",
    "with open(\"malware_lab_files/models/ember_weights.txt\", \"wb\") as f:\n",
    "    f.write(ember_pretrained_weights)\n",
    "with open(\"malware_lab_files/models/at_ember_weights.txt\", \"wb\") as f:\n",
    "    f.write(at_ember_pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Ignoring unrecognized parameter 'max_conflict_rate' found in model string.\n",
      "[LightGBM] [Warning] Ignoring unrecognized parameter 'sparse_threshold' found in model string.\n",
      "[LightGBM] [Warning] Ignoring unrecognized parameter 'enable_load_from_binary_file' found in model string.\n",
      "[LightGBM] [Warning] Ignoring unrecognized parameter 'max_position' found in model string.\n"
     ]
    }
   ],
   "source": [
    "from secml_malware.models.c_classifier_ember import CClassifierEmber\n",
    "from secml_malware.attack.blackbox.c_wrapper_phi import CEmberWrapperPhi\n",
    "\n",
    "gbdt = CEmberWrapperPhi(CClassifierEmber(\"malware_lab_files/models/ember_weights.txt\"))\n",
    "at_gbdt = CEmberWrapperPhi(CClassifierEmber(\"malware_lab_files/models/at_ember_weights.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-] File havoc_demon not found in archive malware_lab_files/binaries/havoc_demon.7z, providing all files as {<file_name>: <file_content>}\n",
      "Evaluating e430acd25056f7616cee8ce7b399302658a75450077622555376e69fb6aa37ca.orig.7z\n",
      "GBDT:\t\t 0.9980717859661449\n",
      "AT-GBDT:\t 0.9999952278284678\n",
      "\n",
      "Evaluating 5e3588e8ddebd61c2bd6dab4b87f601bd6a4857b33eb281cb5059c29cfe62b80.7z\n",
      "GBDT:\t\t 0.8948956622503857\n",
      "AT-GBDT:\t 0.9999834790049872\n",
      "\n",
      "Evaluating 0d219aa54b1d417da61bd4aed5eeb53d6cba91b3287d53186b21fed450248215.7z\n",
      "GBDT:\t\t 0.12335328209917926\n",
      "AT-GBDT:\t 0.9968451984074367\n",
      "\n",
      "Evaluating 57edf6f6ca18699cd4667e5d314fd6370d48a3733b266857ed6123d093b064a7.orig.7z\n",
      "GBDT:\t\t 0.9999843696065638\n",
      "AT-GBDT:\t 0.9999376384783011\n",
      "\n",
      "Evaluating a1f263efc7aa942f57a32b0e9095aeb654d6bbc2f25cc00ee195c2fd81520aa4.orig.7z\n",
      "GBDT:\t\t 0.9999999516783914\n",
      "AT-GBDT:\t 0.9999999630888408\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from secml.array import CArray\n",
    "from secml.data import CDataset\n",
    "from secml_malware.models.basee2e import End2EndModel\n",
    "from pathlib import Path\n",
    "\n",
    "def load_malware_samples(max_size=2000000, padding_val=0, shift_val=True):\n",
    "    path = Path(\"malware_lab_files\") / \"binaries\"\n",
    "    X = []\n",
    "    Y = []\n",
    "    names = []\n",
    "    for file in path.glob(\"*.7z\"):\n",
    "        if \"adv\" in file.name:\n",
    "            continue\n",
    "        s = get_encrypted_archive(str(file), password=\"infected\")\n",
    "        if isinstance(s, dict):\n",
    "            s = s[list(s.keys())[0]]\n",
    "            continue\n",
    "        names.append(file)\n",
    "        X.append(End2EndModel.bytes_to_numpy(s, max_size, padding_val, shift_val))\n",
    "        Y.append(1)\n",
    "    X = CArray(X)\n",
    "    Y = CArray(Y)\n",
    "    return CDataset(X,Y), names\n",
    "\n",
    "\n",
    "malware_dataset, names = load_malware_samples(padding_val=256, shift_val=False)\n",
    "for i in  range(malware_dataset.X.shape[0]):\n",
    "    print(f\"Evaluating {names[i].name}\")\n",
    "    print(\"GBDT:\\t\\t\", gbdt.predict(malware_dataset.X[i,:])[1][0,1].item())\n",
    "    print(\"AT-GBDT:\\t\", at_gbdt.predict(malware_dataset.X[i,:])[1][0,1].item())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AT model seems already to be more effective than its undefended counterpart.\n",
    "This is due to the extra data used at training time.\n",
    "\n",
    "**However** the AT model is costly to train, since you need to compute attacks for a large portion of your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secml_malware.attack.blackbox.c_gamma_evasion import CGammaEvasionProblem\n",
    "\n",
    "content, source_file = CGammaEvasionProblem.create_section_population_from_folder(\"malware_lab_files/benignware\", 50, size_lower_bound=256, sections_to_extract=[\".data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robust Accuracy: 20.00%\n",
      "Scores: [[0.6373266529504729], [0.13669227324693323], [0.33450027010958294], [0.16352011476657338], [0.9999359452830275]]\n"
     ]
    }
   ],
   "source": [
    "from secml_malware.attack.blackbox.c_gamma_sections_evasion import CGammaSectionsEvasionProblem\n",
    "from secml_malware.attack.blackbox.ga.c_base_genetic_engine import CGeneticAlgorithm\n",
    "\n",
    "gamma_section_injection = CGammaSectionsEvasionProblem(content, gbdt, population_size=10, penalty_regularizer=1e-6, iterations=10)\n",
    "engine = CGeneticAlgorithm(gamma_section_injection)\n",
    "gamma_sect_pred, gamma_sect_scores, _, _ = engine.run(malware_dataset.X, malware_dataset.Y)\n",
    "\n",
    "print(f\"Robust Accuracy: {gamma_sect_pred.mean()*100:.2f}%\")\n",
    "print(f\"Scores: {gamma_sect_scores[:,1].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robust Accuracy: 100.00%\n",
      "Scores: [[0.9999895741544117], [0.9999998165158442], [0.9999843154784305], [0.9981858554057478], [0.9999984418165898]]\n"
     ]
    }
   ],
   "source": [
    "from secml_malware.attack.blackbox.c_gamma_sections_evasion import CGammaSectionsEvasionProblem\n",
    "from secml_malware.attack.blackbox.ga.c_base_genetic_engine import CGeneticAlgorithm\n",
    "\n",
    "at_gamma_section_injection = CGammaSectionsEvasionProblem(content, at_gbdt, population_size=10, penalty_regularizer=1e-6, iterations=10)\n",
    "at_engine = CGeneticAlgorithm(at_gamma_section_injection)\n",
    "at_gamma_sect_pred, at_gamma_sect_scores, _, _ = at_engine.run(malware_dataset.X, malware_dataset.Y)\n",
    "\n",
    "print(f\"Robust Accuracy: {at_gamma_sect_pred.mean()*100:.2f}%\")\n",
    "print(f\"Scores: {at_gamma_sect_scores[:,1].tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown by this simple experiment, AT model is incredibly more robust than the undefended model.\n",
    "\n",
    "However, the time required to create EXEmples is not negligible.\n",
    "Thus, the creation of robust models is a tradeoff between the needed robustness and the resources your are willing to spend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
