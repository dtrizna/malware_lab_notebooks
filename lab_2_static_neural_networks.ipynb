{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIEL4OAWb4vA"
      },
      "source": [
        "# Black Hat USA 2024 Training\n",
        "\n",
        "## Lab 2: Feature Extraction from Byte Level Data with Neural Networks and PyTorch\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/dtrizna/malware_lab_notebooks/blob/main/lab_2_static_neural_networks.ipynb)\n",
        "\n",
        "In this lab we will work with PyTorch Neural Network to process byte level data from a PE file, with intent to classify it as malicious or benign. We will use a pre-trained model called MalConv, which is a convolutional neural network released in 2017 by Raff et al. We will use the same sample as in Lab 1 and observe the pre-processing and modeling steps to clearly differentiate between feature extraction and byte-level modeling. \n",
        "\n",
        "Additionally, we will cover basic PyTorch concepts, how to define a neural network model in PyTorch, and explore path of PE sample through the neural network. Finally, we will discuss explainability of neural networks and how to interpret the results.\n",
        "\n",
        "Contents:\n",
        "- Downloading AsyncRAT Sample\n",
        "- Pre-Trained MalConv Model\n",
        "- PyTorch Introduction\n",
        "- PE File Path through Neural Network:\n",
        "  - Embeddings\n",
        "  - Convolutional Neural Network\n",
        "  - Linear Layers\n",
        "- Defining a PyTorch Model\n",
        "- Explainability\n",
        "\n",
        "First, download pre-requisites and import necessary libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rnt7qp0Pb4vE",
        "outputId": "0067372f-ee27-485b-86b8-1ad153e35d15"
      },
      "outputs": [],
      "source": [
        "!rm -rf malware_lab_files\n",
        "!git clone https://github.com/dtrizna/malware_lab_files.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zyp9ya0b4vG",
        "outputId": "977edc5e-6c95-4354-c11c-587232574523"
      },
      "outputs": [],
      "source": [
        "%pip install requests numpy yara-python py7zr==0.19.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "d-n34tiwb4vH"
      },
      "outputs": [],
      "source": [
        "import sys # force reimport of lab_helpers\n",
        "if 'malware_lab_files.helpers' in sys.modules:\n",
        "    del sys.modules['malware_lab_files.helpers']\n",
        "\n",
        "from malware_lab_files.helpers import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRqI0M8Nb4vH"
      },
      "source": [
        "### Downloading AsyncRAT Sample\n",
        "\n",
        "We will use the same sample as in Lab 1, to allow us a direct comparison of results. The sample download is as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hq_0N4Mvb4vI",
        "outputId": "f37d7c24-bbf0-417a-d967-37bf9fa9362f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "b'MZ\\x90\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\xff\\xff\\x00\\x00\\xb8\\x00\\x00\\x00'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# vx-underground link for reference\n",
        "vx_link = \"https://samples.vx-underground.org/Samples/Families/AsyncRAT/5e3588e8ddebd61c2bd6dab4b87f601bd6a4857b33eb281cb5059c29cfe62b80.7z\"\n",
        "\n",
        "# using a local copy\n",
        "import os\n",
        "async_rat_local_path = os.path.join(\"malware_lab_files\", \"binaries\", \"5e3588e8ddebd61c2bd6dab4b87f601bd6a4857b33eb281cb5059c29cfe62b80.7z\")\n",
        "async_rat_bytez = get_encrypted_archive(async_rat_local_path, password=\"infected\")\n",
        "\n",
        "async_rat_bytez[0:20]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnFqCoScb4vK"
      },
      "source": [
        "## Pre-Trained MalConv Model\n",
        "\n",
        "MalConv is a binary classifier model that outputs a probability of the sample being malicious, proposed by group of researchers in this [paper](https://arxiv.org/abs/1710.09435) by Raff et al. Under the hood it is a convolutional neural network (CNN) that extracts low-level features from the byte sequence of the malware sample. Schematic view of the model is as follows:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1oRheR-7NkMXYGgTZS5RcWse5S0RcnfaL\" width=\"600\">\n",
        "\n",
        "<!-- <img src=\"./malware_lab_files/img/malconv.png\" width=\"600\"> -->\n",
        "\n",
        "Let's download the pre-trained model and verify predictions on the AsyncRAT sample:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQ1VKvnsb4vL",
        "outputId": "f6eed0ee-2c87-42e1-f552-d25065b90d41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[+] Downloaded MalConv weights | Size: 24.79 MB\n"
          ]
        }
      ],
      "source": [
        "malconv_local_path = os.path.join(\"malware_lab_files\", \"models\", \"malconv.checkpoint\")\n",
        "with open(malconv_local_path, \"rb\") as f:\n",
        "    malconv_weights = f.read()\n",
        "\n",
        "print(f\"[+] Loaded MalConv weights | Size: {len(malconv_weights) / 1024 / 1024:.2f} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7sWtZlFKb4vM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.manual_seed(0)\n",
        "\n",
        "malconv = MalConvModel()\n",
        "malconv.load_state(malconv_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAMxWSr1b4vM",
        "outputId": "6759779b-df21-4568-9b0a-af3a528e0806"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MalConv(\n",
              "  (embd): Embedding(257, 8, padding_idx=0)\n",
              "  (conv_1): Conv1d(8, 256, kernel_size=(512,), stride=(512,))\n",
              "  (conv_2): Conv1d(8, 256, kernel_size=(512,), stride=(512,))\n",
              "  (pooling): AdaptiveMaxPool1d(output_size=1)\n",
              "  (fc_1): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (fc_2): Linear(in_features=256, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "malconv.model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Yx7kvswcch8",
        "outputId": "db45eff8-5c6f-45bc-af6b-e8f6e71355e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[+] MalConv probability for Async RAT sample being malware: 63.90%\n"
          ]
        }
      ],
      "source": [
        "score = malconv.get_score(async_rat_bytez)\n",
        "print(f\"[+] MalConv probability for Async RAT sample being malware: {score*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gj51HgQlb4vN"
      },
      "source": [
        "MalConv is neural network, and to understand how it works under the hood, we need to grasp basics of PyTorch.\n",
        "\n",
        "## PyTorch Introduction\n",
        "\n",
        "PyTorch is a Python library for implementing Deep Learning models. Deep Learning is a subfield of Machine Learning that uses **Neural Networks** to learn complex patterns in data.\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1eeErAC3cPBIby3rSSw2sy4lHblg3r0Hy\" width=\"400\">\n",
        "\n",
        "<!-- <img src=\"./malware_lab_files/img/ai_ml_dl.png\" width=\"400\"> -->\n",
        "\n",
        "During last years PyTorch became a de-facto standard for Deep Learning research, substituting the previous leader TensorFlow. PyTorch is a very flexible library that allows to implement complex models with a few lines of code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtug-rJfb4vN"
      },
      "source": [
        "### Tensors\n",
        "\n",
        "Any deep learning framework operate with tensors, which are multi-dimensional arrays. In PyTorch, tensors are the main data structure. They are similar to NumPy arrays, but with additional features that make them suitable for deep learning:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1N3UTt2Xyvi09yn5582ClFx93Pw1uegjT\" width=\"600\">\n",
        "\n",
        "<!-- <img src=\"./malware_lab_files/img/tensors.png\" width=\"600\"> -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwLHQZIcb4vO",
        "outputId": "070e0010-3511-43a3-d58c-23ae55cf0da2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([9])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# 1-D tensor (aka vector)\n",
        "tensor_a = torch.Tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
        "print(tensor_a.shape)\n",
        "tensor_a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sg3y2TsZb4vO",
        "outputId": "6714e796-1536-4c21-dd42-94aa26562637"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 3])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[1., 2., 3.],\n",
              "        [4., 5., 6.],\n",
              "        [7., 8., 9.]])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 2-D tensor (aka matrix)\n",
        "tensor_b = tensor_a.reshape(3, 3)\n",
        "print(tensor_b.shape)\n",
        "tensor_b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rskHSGoDb4vO",
        "outputId": "b914c48f-692d-407f-ed3d-2287c7cacc17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 3, 3])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[[1., 2., 3.],\n",
              "         [4., 5., 6.],\n",
              "         [7., 8., 9.]],\n",
              "\n",
              "        [[1., 2., 3.],\n",
              "         [4., 5., 6.],\n",
              "         [7., 8., 9.]],\n",
              "\n",
              "        [[1., 2., 3.],\n",
              "         [4., 5., 6.],\n",
              "         [7., 8., 9.]]])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_c = torch.vstack([tensor_a, tensor_a, tensor_a]).reshape(3, 3, 3)\n",
        "print(tensor_c.shape)\n",
        "tensor_c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMb5pfdKb4vP"
      },
      "source": [
        "### Layers\n",
        "\n",
        "#### Embeddings\n",
        "\n",
        "Now, let's see how we can use PyTorch to extract features from the byte level of the malware sample. First, raw MZ file bytes are converted to an integer array:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaSj6G2Fb4vP",
        "outputId": "7d7c522c-2d00-49f4-cb65-5b241a7125e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 77,  90, 144,   0,   3], dtype=torch.uint8)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "FIRST_N_BYTES = 5\n",
        "torch.tensor( np.frombuffer(async_rat_bytez, dtype=np.uint8)[0:FIRST_N_BYTES].copy() )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdGUOPtUb4vQ"
      },
      "source": [
        "We can confirm that the first bytes of the file are indeed the MZ header:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOLr63Xvb4vQ",
        "outputId": "f3f3f467-4583-4c85-8835-f2449429ee65"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "b'MZ\\x90\\x00\\x03'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bytes([77, 90, 144, 0, 3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olJoqG8zb4vQ"
      },
      "source": [
        "In absolute majority of neural network architectures suited for textual analysis, first layer is an **Embedding** layer. Embeddings are basically a lookup table that maps each byte to a vector representation, learned during the training process. Important property of embedded vectors is that after training similar inputs are mapped to similar locations in the embedded vectorspace, as depicted in the following figure which displays **3-dimensional embeddings**:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1857l63Hovs_ZuAbc6trDLKzE44OY9_yw\" width=\"700\">\n",
        "\n",
        "<!-- <img src=\"./malware_lab_files/img/embedding_star_wars.gif\" width=\"600\"> -->\n",
        "\n",
        "[[Image Source]](https://medium.com/@marcusa314/visualizing-words-377624cb20c7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWAysfyIb4vQ"
      },
      "source": [
        "MalConv uses **embedding size of 8**, but it is common to use higher dimensionality in modern models, such as 64 or 128.\n",
        "\n",
        "Let's define an 8-dimensional embedding layer and pass the first 5 bytes of the AsyncRAT sample through it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxev8QO-b4vQ",
        "outputId": "d4be994b-f6d3-4867-98fa-2e9f006e248c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[!] Shape of data before embedding: torch.Size([5])\n"
          ]
        }
      ],
      "source": [
        "# get the embedding for the first 5 bytes of the Async RAT sample\n",
        "async_first_5_bytez = torch.tensor([77, 90, 144, 0, 3])\n",
        "print(f\"[!] Shape of data before embedding: {async_first_5_bytez.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11XdhNvrb4vR"
      },
      "source": [
        "In the embedded array each byte is expanded to a 8-dimensional vector:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_6PQBDjb4vR",
        "outputId": "aad1dc4f-e43e-47bb-c528-251bc6db2580"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[!] Shape of data after embedding: torch.Size([5, 8])\n"
          ]
        }
      ],
      "source": [
        "# embedding that encodes each byte to 8 dimensions, 256 possible values\n",
        "nr_of_bytes = 256\n",
        "embedding_size = 8\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# define Embedding layer in PyTorch\n",
        "example_embed = torch.nn.Embedding(nr_of_bytes, embedding_size)\n",
        "\n",
        "print(f\"[!] Shape of data after embedding: {example_embed(async_first_5_bytez).shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgVADGHvb4vR",
        "outputId": "292c1a88-2305-461f-9cfc-60ce996cdd17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[!] Data after embedding:\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[-0.7650, -0.4750, -0.4953, -0.1984,  2.2149, -0.1367, -1.0182,  0.1784],\n",
              "        [ 0.7049,  0.0305, -0.8542,  0.5388, -0.5265, -1.3320,  1.5451,  0.4086],\n",
              "        [ 0.4047, -0.6549,  0.0521,  0.3401, -0.2124,  1.5629, -0.9072, -1.5662],\n",
              "        [-1.1258, -1.1524, -0.2506, -0.4339,  0.8487,  0.6920, -0.3160, -2.1152],\n",
              "        [ 0.7502, -0.5855, -0.1734,  0.1835,  1.3894,  1.5863,  0.9463, -0.8437]],\n",
              "       grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(f\"[!] Data after embedding:\\n\")\n",
        "\n",
        "example_embed(async_first_5_bytez)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVJKanrBb4vS",
        "outputId": "57d66a11-3491-4131-bc2d-0c3ae6271fa6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[!] First byte: 77\n",
            "[!] First byte's embedding: tensor([-0.7650, -0.4750, -0.4953, -0.1984,  2.2149, -0.1367, -1.0182,  0.1784])\n"
          ]
        }
      ],
      "source": [
        "first_byte = async_first_5_bytez[0]\n",
        "with torch.no_grad():\n",
        "    first_byte_embed = example_embed(async_first_5_bytez)[0]\n",
        "\n",
        "print(f\"[!] First byte: {first_byte}\")\n",
        "print(f\"[!] First byte's embedding: {first_byte_embed}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQ4cMEMMb4vS"
      },
      "source": [
        "The idea should be clear by now. Now, we need more representative information size -- take **first 200000 bytes** of the AsyncRAT sample and pass it through the embedding layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "670kDLF0b4vT",
        "outputId": "d9491a7f-39f5-4fcc-8838-dd88f73e1a0b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 200000])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "asyncrat_tensor = torch.tensor(np.frombuffer(async_rat_bytez, dtype=np.uint8)[np.newaxis,:].copy())[:, :200000]\n",
        "asyncrat_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHqaJV4Hb4vT",
        "outputId": "aa623081-f34e-4603-fa47-ea701a08cbeb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 200000, 8])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "asyncrat_embedded = example_embed(asyncrat_tensor.long())\n",
        "asyncrat_embedded.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SalATrrb4vU"
      },
      "source": [
        "#### Convolutional Layer\n",
        "\n",
        "In MalConv, the output of the embedding layer is passed to a 1D convolutional layer, that take a raw byte sequence and extracts features from the byte sequence by applying a filter to a window of bytes at a time.\n",
        "\n",
        "1D convolutional example below depicts input with **embedding size** of **3**, and convolution having **kernel size** is **3** with **stride** of **1**:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1ssbaa4YvfzPrCK2n-BWlcM_-xJ2TdMKB\" width=\"600\">\n",
        "\n",
        "<!-- <img src=\"./malware_lab_files/img/conv_1D_time.gif\" width=\"600\"> -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcUGcF-Mb4vX"
      },
      "source": [
        "We need to transpose the array to match the input shape of the convolutional layer, which expects the input dimensions to be:\n",
        "\n",
        "`(batch_size, embedding_size, sequence_length)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEaexkOUb4vY",
        "outputId": "0240c138-3702-41f9-da0f-2907fce7ed39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[!] Shape of data before 1D convolutional layer: torch.Size([1, 8, 200000])\n"
          ]
        }
      ],
      "source": [
        "# switch the 1st and 2nd dimensions\n",
        "asyncrat_embedded_prep = torch.transpose(asyncrat_embedded, 2, 1)\n",
        "\n",
        "print(f\"[!] Shape of data before 1D convolutional layer: {asyncrat_embedded_prep.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wd2SKtumb4va"
      },
      "source": [
        "MalConv uses 1D convolutional layer with a **kernel size of 512**, applies 256 filters (number of independent convolutional extractors), and uses **stride** of **512**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "UQqTKo4eb4va"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "conv_layer = torch.nn.Conv1d(\n",
        "    in_channels=8,\n",
        "    out_channels=256,\n",
        "    kernel_size=512,\n",
        "    stride=512\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBjk6hFYb4va"
      },
      "source": [
        "Because of the stride, sequence length from original 200000 bytes are reduced to 390, with 256 independent convolutions applied to each window of 512 bytes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVifXduCb4vb",
        "outputId": "8da6fd04-2c62-4f4c-879b-4b76e583fc14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[!] Shape of data after 1D convolutional layer: torch.Size([1, 256, 390])\n"
          ]
        }
      ],
      "source": [
        "print(f\"[!] Shape of data after 1D convolutional layer: {conv_layer(asyncrat_embedded_prep).shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4wwJ_KNb4vb",
        "outputId": "9b715768-c86a-4f9f-e1a2-16cd46f90084"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[-0.3150,  0.1721,  0.0220,  ...,  0.9214,  0.5167, -0.5706],\n",
              "         [ 0.2943, -0.6932,  0.0379,  ...,  0.1647, -0.0668, -0.0521],\n",
              "         [ 0.0768, -0.9937,  0.2447,  ...,  0.3427, -0.8050, -0.1158],\n",
              "         ...,\n",
              "         [-0.0962, -0.2683,  1.5979,  ..., -0.9385,  0.0210, -1.0429],\n",
              "         [ 0.5865, -0.1245,  0.1460,  ..., -0.9941,  0.0721, -0.5876],\n",
              "         [-0.0677, -0.4522, -1.1285,  ...,  0.5529,  0.1676, -0.9465]]],\n",
              "       grad_fn=<ConvolutionBackward0>)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conv_layer(asyncrat_embedded_prep)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do4vPC8fb4vc"
      },
      "source": [
        "Each element in this output tensor is single number representation of 512 bytes of the original sample, extracted by the convolutional layer.\n",
        "\n",
        "This tensor is then passed through a max pooling layer, which takes the maximum value from each filter output, reducing the tensor to a single dimension.\n",
        "\n",
        "### Linear Layers\n",
        "\n",
        "Finally, the output is passed through a fully connected (aka **Linear**) layers, which is a standard neural network living in everyone heads:\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1qfH8q9o8qg1W4QhDWO29tL_3e2sDRjUT\" width=\"300\">\n",
        "\n",
        "<!-- <img src=\"./malware_lab_files/img/linear.png\" width=\"300\"> -->\n",
        "\n",
        "Linear layers can be considered as knowledge base of the model. These layers learn convoluted feature mapping to an actual label, and are used to make the final prediction of the sample being malicious or benign.\n",
        "\n",
        "`MalConv` stacks two linear layers with **ReLU** activation function in between, and a final linear layer with **Sigmoid** activation function to output the probability of the sample being malicious:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqKWS55Cb4vc",
        "outputId": "b6b823b9-f29a-4953-86c9-f2a58902d391"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[!] Shape of data after 1D conv. layer:\t     torch.Size([1, 256, 390])\n",
            "[!] Shape of data after max pooling:\t     torch.Size([1, 256, 1])\n",
            "[!] Shape of data after first linear layer:  torch.Size([1, 256])\n",
            "[!] Shape of data after second linear layer: torch.Size([1, 1])\n",
            "\n",
            "[!] Final probability of Async RAT sample being malware:\n",
            "\n",
            "62.57%\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(0)\n",
        "from torch import nn\n",
        "\n",
        "print(f\"[!] Shape of data after 1D conv. layer:\\t     {conv_layer(asyncrat_embedded_prep).shape}\")\n",
        "\n",
        "pooling = nn.AdaptiveMaxPool1d(1)\n",
        "pooled = pooling(conv_layer(asyncrat_embedded_prep))\n",
        "print(f\"[!] Shape of data after max pooling:\\t     {pooled.shape}\")\n",
        "\n",
        "linear_1 = nn.Linear(256, 256)\n",
        "linear_1_out = torch.relu(linear_1(pooled.view(-1, 256)))\n",
        "print(f\"[!] Shape of data after first linear layer:  {linear_1_out.shape}\")\n",
        "\n",
        "linear_2 = nn.Linear(256, 1)\n",
        "logit = linear_2(linear_1_out)\n",
        "print(f\"[!] Shape of data after second linear layer: {logit.shape}\")\n",
        "\n",
        "probability = torch.sigmoid(logit)\n",
        "print(f\"\\n[!] Final probability of Async RAT sample being malware:\\n\\n{probability[0].item()*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUYIqwuUb4vj"
      },
      "source": [
        "## Defining PyTorch Model\n",
        "\n",
        "Let's put all these layers together to form an actual Neural Network model that can learn byte level features from the PE samples and identify malicious patterns. We will use the same model as in the original MalConv paper which uses few extra additions to previously described components."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ky4Eparmb4vk"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class MalConv(nn.Module):\n",
        "    # trained to minimize cross-entropy loss: criterion = nn.CrossEntropyLoss()\n",
        "    def __init__(\n",
        "            self,\n",
        "            embd_size=8, # dimensionality of the byte embeddings\n",
        "            total_nr_of_bytes=256, # number of possible byte values\n",
        "            channels=256, # number of independent channels in the convolutional layer\n",
        "            window_size=512, # size of the convolutional window\n",
        "            stride=512, # stride (jump length) of the convolutional window\n",
        "            out_size=2 # size of the output layer, corresponds to the number of classes we want to detect\n",
        "    ):\n",
        "        super(MalConv, self).__init__()\n",
        "        bytes_with_padding = total_nr_of_bytes + 1\n",
        "        self.embd = nn.Embedding(bytes_with_padding, embd_size, padding_idx=0)\n",
        "\n",
        "        self.window_size = window_size\n",
        "\n",
        "        self.conv_1 = nn.Conv1d(embd_size, channels, window_size, stride=stride, bias=True)\n",
        "        self.conv_2 = nn.Conv1d(embd_size, channels, window_size, stride=stride, bias=True)\n",
        "\n",
        "        self.pooling = nn.AdaptiveMaxPool1d(1)\n",
        "\n",
        "        self.fc_1 = nn.Linear(channels, channels)\n",
        "        self.fc_2 = nn.Linear(channels, out_size)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.embd(x.long())\n",
        "        x = torch.transpose(x, 2, 1)\n",
        "\n",
        "        cnn_value = self.conv_1(x)\n",
        "        gating_weight = torch.sigmoid(self.conv_2(x))\n",
        "\n",
        "        x = cnn_value * gating_weight\n",
        "\n",
        "        x = self.pooling(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1) # flatten\n",
        "\n",
        "        x = F.relu(self.fc_1(x))\n",
        "        x = self.fc_2(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8IIzQC_b4vk",
        "outputId": "66ba12f5-d39f-4c81-a093-c716b876fca3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 2])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "with torch.no_grad():\n",
        "    malconv = MalConv()\n",
        "    logits = malconv(asyncrat_tensor)\n",
        "\n",
        "logits.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tm_1vMdZb4vl",
        "outputId": "0e56c23a-23bc-4e76-a09b-17d8cb04ab8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[+] MalConv probability for Async RAT sample being malware: 47.52%\n"
          ]
        }
      ],
      "source": [
        "print(f\"[+] MalConv probability for Async RAT sample being malware: {torch.sigmoid(logits)[0, 1].item()*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7VynFZSb4vl"
      },
      "source": [
        "We haven't loaded the pre-trained model yet -- this is output from the randomly initialized model.\n",
        "\n",
        "We can try to change random seed and verify that for the non-trained model probability changes, but stays highly uncertain, somewhere close to 50% all the time:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0evVvcv1b4vo",
        "outputId": "09e0a7d5-1423-46a8-dd58-a58966e51993"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[!] Seed: 0\n",
            "\tProbability AsyncRAT:    47.88%\n",
            "\tProbability notepad.exe: 49.00%\n",
            "[!] Seed: 1\n",
            "\tProbability AsyncRAT:    52.07%\n",
            "\tProbability notepad.exe: 54.18%\n",
            "[!] Seed: 2\n",
            "\tProbability AsyncRAT:    52.79%\n",
            "\tProbability notepad.exe: 51.92%\n",
            "[!] Seed: 3\n",
            "\tProbability AsyncRAT:    53.16%\n",
            "\tProbability notepad.exe: 52.47%\n",
            "[!] Seed: 4\n",
            "\tProbability AsyncRAT:    47.21%\n",
            "\tProbability notepad.exe: 46.60%\n"
          ]
        }
      ],
      "source": [
        "notepad_path = os.path.join(\"malware_lab_files\", \"benignware\", \"notepad.exe\")\n",
        "with open (notepad_path, \"rb\") as f:\n",
        "    notepad_bytez = f.read()\n",
        "\n",
        "for seed in range(5):\n",
        "    torch.manual_seed(seed)\n",
        "    print(f\"[!] Seed: {seed}\")\n",
        "\n",
        "    malconv = MalConv()\n",
        "\n",
        "    async_rat_logits = malconv(asyncrat_tensor)\n",
        "    print(f\"\\tProbability AsyncRAT: {torch.softmax(async_rat_logits, dim=-1)[0, 1].item()*100:>8.2f}%\")\n",
        "\n",
        "    notepad_tensor = torch.tensor(np.frombuffer(notepad_bytez, dtype=np.uint8)[np.newaxis,:].copy())[:, :200000]\n",
        "    notepad_logits = malconv(notepad_tensor)\n",
        "    print(f\"\\tProbability notepad.exe: {torch.softmax(notepad_logits, dim=-1)[0, 1].item()*100:>5.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHfdCS--b4vl"
      },
      "source": [
        "Let's load the pre-trained model and verify predictions on the AsyncRAT sample:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AL1DUKacb4vm",
        "outputId": "4bcf4e2c-0266-4272-9bd5-39399d9f4024"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import io\n",
        "\n",
        "malconv_weights_dict = torch.load(\n",
        "    io.BytesIO(malconv_weights),\n",
        "    map_location=torch.device('cpu')\n",
        ")\n",
        "malconv.load_state_dict(malconv_weights_dict['model_state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZRaTFwtb4vm",
        "outputId": "a2249804-0580-419a-843a-b5bdb4b84a46"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.3610, 0.6390]])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "async_rat_bytez_200k = async_rat_bytez[:2000000]\n",
        "asyncrat_tensor = torch.tensor(np.frombuffer(async_rat_bytez_200k, dtype=np.uint8)[np.newaxis,:].copy())\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = torch.softmax(malconv(asyncrat_tensor), dim=-1)\n",
        "\n",
        "outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IObxUnDIb4vq"
      },
      "source": [
        "Pre-trained model has the same score and differentiates between malicious and benign samples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_1DigKOb4vq",
        "outputId": "55c2c025-dc82-4821-a42a-ac67a59dd24b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[!] Seed: 0\n",
            "\tProbability AsyncRAT:    63.90%\n",
            "\tProbability notepad.exe: 53.08%\n",
            "[!] Seed: 1\n",
            "\tProbability AsyncRAT:    63.90%\n",
            "\tProbability notepad.exe: 53.08%\n",
            "[!] Seed: 2\n",
            "\tProbability AsyncRAT:    63.90%\n",
            "\tProbability notepad.exe: 53.08%\n",
            "[!] Seed: 3\n",
            "\tProbability AsyncRAT:    63.90%\n",
            "\tProbability notepad.exe: 53.08%\n",
            "[!] Seed: 4\n",
            "\tProbability AsyncRAT:    63.90%\n",
            "\tProbability notepad.exe: 53.08%\n"
          ]
        }
      ],
      "source": [
        "for seed in range(5):\n",
        "    torch.manual_seed(seed)\n",
        "    print(f\"[!] Seed: {seed}\")\n",
        "\n",
        "    malconv = MalConv()\n",
        "\n",
        "    # load the pre-trained weights\n",
        "    malconv_weights_dict = torch.load(\n",
        "        io.BytesIO(malconv_weights),\n",
        "        map_location=torch.device('cpu')\n",
        "    )\n",
        "    malconv.load_state_dict(malconv_weights_dict['model_state_dict'])\n",
        "\n",
        "    asnyc_rat_logits = malconv(asyncrat_tensor)\n",
        "    print(f\"\\tProbability AsyncRAT: {torch.softmax(asnyc_rat_logits, dim=-1)[0, 1].item()*100:>8.2f}%\")\n",
        "\n",
        "    notepad_tensor = torch.tensor(np.frombuffer(notepad_bytez, dtype=np.uint8)[np.newaxis,:].copy())[:, :200000]\n",
        "    notepad_logits = malconv(notepad_tensor)\n",
        "    print(f\"\\tProbability notepad.exe: {torch.softmax(notepad_logits, dim=-1)[0, 1].item()*100:>5.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTMC2wOhb4vs"
      },
      "source": [
        "Note, MalConv is still research prototype and these pre-trained weights are not usable in production environment -- just take a look on prediction over `calc.exe` -- horrible:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIePEi_eb4vt",
        "outputId": "179b13e5-b7ce-450a-cd94-231ab8f1b1ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[+] Probability malicious calc.exe: 98.65%\n"
          ]
        }
      ],
      "source": [
        "calc_path = os.path.join(\"malware_lab_files\", \"benignware\", \"calc.exe\")\n",
        "with open (calc_path, \"rb\") as f:\n",
        "    calc_bytez = f.read()\n",
        "\n",
        "calc_tensor = torch.tensor(np.frombuffer(calc_bytez, dtype=np.uint8)[np.newaxis,:].copy())[:, :200000]\n",
        "calc_logits = malconv(calc_tensor)\n",
        "print(f\"[+] Probability malicious calc.exe: {torch.softmax(calc_logits, dim=-1)[0, 1].item()*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QjJ_elXb4vu"
      },
      "source": [
        "# Explainability\n",
        "\n",
        "We will now explore the model's predictions and try to understand why it classified the AsyncRAT sample as malicious."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class MalConvNoEmbedding(MalConv):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # NOTE: here we removed the embedding layer\n",
        "        # x = self.embd(x.long())\n",
        "        x = torch.transpose(x, 2, 1)\n",
        "        cnn_value = self.conv_1(x)\n",
        "        gating_weight = torch.sigmoid(self.conv_2(x))\n",
        "        x = cnn_value * gating_weight\n",
        "        x = self.pooling(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc_1(x))\n",
        "        x = self.fc_2(x)\n",
        "        return x\n",
        "    \n",
        "\n",
        "malconv_weights_dict = torch.load(\n",
        "    io.BytesIO(malconv_weights),\n",
        "    map_location=torch.device('cpu')\n",
        ")\n",
        "\n",
        "model = MalConv()\n",
        "model.load_state_dict(malconv_weights_dict['model_state_dict'])\n",
        "model.eval()\n",
        "\n",
        "model_no_embed = MalConvNoEmbedding()\n",
        "model_no_embed.load_state_dict(malconv_weights_dict['model_state_dict'])\n",
        "model_no_embed.eval()\n",
        "\n",
        "def embed(torch_model: MalConv, x: torch.Tensor) -> torch.Tensor:\n",
        "    x = torch_model.embd(x.long())\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "# min_shape = min(calc_tensor.shape[1], asyncrat_tensor.shape[1])\n",
        "x = asyncrat_tensor[:, :200000]\n",
        "# baseline_calc = calc_tensor[:, :min_shape]\n",
        "baseline_zeros = torch.zeros_like(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 200000, 8)"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from shap import GradientExplainer\n",
        "\n",
        "x_embed = embed(model, x)\n",
        "\n",
        "embed_baseline = embed(model, baseline_zeros)\n",
        "\n",
        "explainer = GradientExplainer(model_no_embed, data=embed_baseline)\n",
        "\n",
        "explanations = explainer.shap_values(x_embed, nsamples=50)\n",
        "\n",
        "explanations_legit = explanations[0]\n",
        "explanations_malware = explanations[1]\n",
        "\n",
        "explanations_malware.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 200000])"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(200000,)"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "explanations_malware.mean(axis=2).squeeze().shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from copy import deepcopy\n",
        "\n",
        "def plot_shap_values(\n",
        "        shap_values: np.ndarray,\n",
        "        name: str,\n",
        "        range_start: int = 0,\n",
        "        ax: plt.Axes = None\n",
        "):\n",
        "    shap_values = shap_values.mean(axis=2).squeeze()\n",
        "    \n",
        "    pos_idx = shap_values >= 0\n",
        "    neg_index = shap_values < 0\n",
        "    \n",
        "    pos_shap = deepcopy(shap_values)\n",
        "    pos_shap[neg_index] = 0\n",
        "    \n",
        "    neg_shap = deepcopy(shap_values)\n",
        "    neg_shap[pos_idx] = 0\n",
        "\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "    \n",
        "    # shap values is of input size, we will plot only the those in the range\n",
        "    range_end = range_start + 512\n",
        "    x = np.arange(range_start, range_end)\n",
        "    ax.bar(x, pos_shap[range_start:range_end])\n",
        "    ax.bar(x, neg_shap[range_start:range_end])\n",
        "    ax.set_title(name)\n",
        "    ax.set_xlabel(\"Byte position\")\n",
        "    ax.set_ylabel(\"SHAP value\")\n",
        "    return ax\n",
        "\n",
        "\n",
        "def find_most_influential_bytes(shap_values: np.ndarray, top_n: int = 10, positive: bool = True) -> np.ndarray:\n",
        "    shap_values = shap_values.mean(axis=2).squeeze()\n",
        "    print(shap_values.shape)\n",
        "    if positive:\n",
        "        return np.argsort(shap_values)[::-1][:top_n]\n",
        "    else:\n",
        "        return np.argsort(shap_values)[:top_n]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Most influential bytes for malware: [10016, 10181, 23054, 23062, 23404, 23455, 23515, 77610, 131607, 131668, 131745, 132030, 135908, 167021, 173593, 173825, 174070, 193648, 193813, 193974]\n"
          ]
        }
      ],
      "source": [
        "explanations_malware_mean = explanations_malware.mean(axis=2).squeeze()\n",
        "idxs = np.argsort(explanations_malware_mean)[::-1][0:20]\n",
        "print(f\"Most influential bytes for malware: {sorted(idxs.tolist())}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_hex_offset(byte_idx: int) -> str:\n",
        "    # returnx 0x0000 format\n",
        "    return f\"0x{byte_idx:04x}\"\n",
        "\n",
        "def bytes_to_hex(bytes_: bytes) -> str:\n",
        "    return \" \".join([f\"{byte:02x}\" for byte in bytes_])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "ax = plot_shap_values(explanations_malware, \"\", range_start=23040)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'0x5a00'"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "find_hex_offset(23040)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'0b 12 00 28 31 00 00 06 38 af 00 00 00 09 13 04'"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bytes_to_hex(asyncrat_tensor[0][23040:23040+16])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "b'\\x0b\\x12\\x00(1\\x00\\x00\\x068\\xaf\\x00\\x00\\x00\\t\\x13\\x04'"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "async_rat_bytez[23040:23040+16]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "ax = plot_shap_values(explanations_malware, \"\", range_start=131607)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'0x20217'"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "find_hex_offset(131607)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'30 56 7f 11 02 05 0d 2d 76 29 2c 31 36 38 5c 7c'"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bytes_to_hex(asyncrat_tensor[0][131607:131607+16].numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "b'0V\\x7f\\x11\\x02\\x05\\r-v),168\\\\|'"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "async_rat_bytez[131607:131607+16]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "ax = plot_shap_values(explanations_malware, \"\", range_start=173593)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'7a 57 e3 35 43 61 f5 9a ca cd f3 51 bb 0a 87 3a'"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bytes_to_hex(asyncrat_tensor[0][173593:173593+16].numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "b'zW\\xe35Ca\\xf5\\x9a\\xca\\xcd\\xf3Q\\xbb\\n\\x87:'"
            ]
          },
          "execution_count": 120,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "async_rat_bytez[173593:173593+16]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
